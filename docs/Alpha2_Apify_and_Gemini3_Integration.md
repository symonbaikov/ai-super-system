# Совместная работа Apify и Gemini 3 — Инструкция

Эта инструкция описывает, как в будущем можно без конфликтов использовать Apify и Gemini 3 вместе в одной системе Alpha-2. Архитектура уже построена модульно, поэтому оба источника и оба ИИ-провайдера могут работать параллельно.

---

## 1. Фиче-флаги в .env

Добавьте или оставьте следующие настройки, чтобы управлять включением модулей и ИИ-провайдеров:

```bash
ENABLE_APIFY=true
ENABLE_SOCIAL_INTAKE=true  # включает приём данных от парсера / DataImpulse
AI_PROVIDER=gemini  # провайдер-адаптер: gemini | groq | openai
```

---

## 2. Два независимых входа данных

Apify и наш собственный парсер могут работать параллельно и не мешают друг другу:

- **Apify** → FastAPI → `/api/apify/callback` → очередь `apify:jobs`
- **Наш парсер** → FastAPI → `/api/intake/social` → очередь `social:jobs`

Обе очереди проходят через один нормализатор, который сохраняет данные в Postgres (таблица `Candidate`) и отправляет события в Redis. UI получает уже объединённый результат.

---

## 3. Единый нормализатор и защита от дубликатов

Worker автоматически объединяет данные и исключает повторы:

- Upsert по ключам (`source_id`, `source`, `ts`)
- Хэширование (`text|link|contract`) — чтобы не создавать дубликаты
- Все источники приводятся к единому формату `Candidate`

---

## 4. Адаптер ИИ (провайдер-слой)

Роут `/api/ai/infer` остаётся универсальным и не зависит от конкретной модели. FastAPI просто читает значение переменной `AI_PROVIDER` из `.env` и направляет запрос в нужный API (Gemini, Groq или OpenAI).

Пример конфигурации:

```bash
AI_PROVIDER_PRIMARY=gemini
AI_PROVIDER_FALLBACK=groq
```

Если основной провайдер временно недоступен, система автоматически переключится на резервный (fallback).

---

## 5. Ограничение частоты и бюджетов

Каждый источник (Apify и Social Intake) имеет собственные лимиты и квоты токенов. Система учитывает дневной бюджет и поддерживает механизм backoff (автопауза при превышении лимита).

---

## 6. UI без изменений

Интерфейс Alpha-2 получает уже объединённые данные через те же эндпоинты:

```
/api/metrics
/api/helius/mints
/api/whales/top3
/api/alerts
/api/signals
```

Для UI неважно, откуда пришли данные — он отображает финальные обработанные сигналы и аналитику.

---

## 7. Тест включения обоих модулей

Чтобы проверить работу Apify и Social Intake вместе:

### 1. В `.env`

```bash
ENABLE_APIFY=true
ENABLE_SOCIAL_INTAKE=true
```

### 2. Отправить тестовые данные

- одно событие через Apify callback
- одно событие через `/api/intake/social`

### 3. Проверить в UI

Вкладка «Сигналы» — оба события должны появиться.

### 4. Проверить Redis

```bash
redis-cli LLEN apify:jobs
redis-cli LLEN social:jobs
```

→ оба значения должны быть 0 (очереди обработаны).

---

## 8. Итог

✅ Оба источника могут работать одновременно  
✅ Один общий ИИ-слой (Gemini 3 основной, Groq резерв)  
✅ Единая база кандидатов и аналитика  
✅ UI получает полную картину без изменений кода  
⚙️ Можно быстро включать/отключать любой модуль через `.env`
